---
title: "Predicting Attitudes Towards Racist College Professors"
author: "Julia Du"
date: "`r lubridate::today()`"
output: 
  github_document:
    toc: true
---

## Load necessary libraries

```{r packages}
library(tidyverse)
library(tidymodels)
library(rcfss)
library(usemodels)
library(kknn)
library(glmnet)
library(xgboost)
library(vip)
library(lubridate)

# load correct gss data frame
data("gss", package = "rcfss")

theme_set(theme_minimal())
```

```{r oof}
# setting seed for all of this doc
set.seed(123)

# splitting data
gss_split <- initial_split(gss, strata = colrac)

gss_train <- training(gss_split)
gss_test <- testing(gss_split)

folds <- vfold_cv(gss_train, v = 10)
```

CHECK THAT I DON'T NEED TO PRE-PROCESS this logistic model
```{r log_reg}
# build a log model specification
lr_mod <- logistic_reg() %>% 
  set_engine("glm")

# resample via a workflow
colrac_lr_wf <- workflow() %>%
  add_model(lr_mod) %>%
  add_formula(colrac ~ 
                age + black + degree + partyid_3 + sex + south)

lr_fit_rs <- colrac_lr_wf %>%
  fit_resamples(folds)

lr_fit_rs %>%
  collect_metrics() %>%
  filter(.metric == "accuracy")
```
Accuracy pretty dang low, man!

```{r random_forest}
# random forest template  
# doesn't actually do anything, but good for reference
#use_ranger(colrac  ~ ., data = gss_train, verbose = TRUE, tune = FALSE)

# build a random forest model specification
rf_mod <- rand_forest(trees = 1000) %>% 
  set_engine("ranger") %>% 
  set_mode("classification")

## do i need TREES IN MY MODEL?

rf_rec <- recipe(colrac ~ ., data = gss_train) %>% 
  update_role(id, wtss, new_role = "ID") %>%
  step_naomit(colrac, skip = TRUE) %>%
  step_medianimpute(all_numeric()) %>%
  step_modeimpute(all_nominal(), -all_outcomes()) %>%
  step_cut(cohort, breaks = c(1945, 1964, 1980))

rf_wf <- workflow() %>%
  add_model(rf_mod) %>%
  add_recipe(rf_rec)

rf_rs <- rf_wf %>%
  fit_resamples(folds) 

rf_rs %>%
  collect_metrics() %>% 
  filter(.metric == "accuracy")
```


```{r knn}
# template for kknn
#use_kknn(colrac ~ ., data = gss_train, verbose = TRUE, tune = FALSE)

knn_mod <- nearest_neighbor(neighbors = 5) %>%              
  set_engine("kknn") %>%             
  set_mode("classification")      

knn_rec <- recipe(formula = colrac ~ ., data = gss_train) %>% 
  update_role(id, wtss, new_role = "ID") %>%
  step_naomit(colrac, skip = TRUE) %>%
  step_medianimpute(all_numeric()) %>%
  step_modeimpute(all_nominal(), -all_outcomes()) %>%
  step_cut(cohort, breaks = c(1945, 1964, 1980)) %>%
  step_novel(all_nominal(), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_zv(all_predictors()) %>% 
  step_normalize(all_predictors(), -all_nominal()) 

knn_wf <- workflow() %>%
  add_model(knn_mod) %>%
  add_recipe(knn_rec)

knn_rs <- knn_wf %>%
  fit_resamples(folds) 

knn_rs %>%
  collect_metrics() %>%
  filter(.metric == "accuracy")
```


```{r ridge}
ridge_mod <- logistic_reg(penalty = .01, mixture = 0) %>% 
  set_engine("glmnet") %>% # use glmnet over glm since we have a penalty
  set_mode("classification")

# using same recipe as knn
ridge_rs <- update_model(knn_wf, ridge_mod) %>%
  fit_resamples(folds) 

ridge_rs %>%
  collect_metrics() %>%
  filter(.metric == "accuracy")
```
```{r tune_boost_tree, cache = TRUE}
boost_tune_spec <- 
  boost_tree(
    min_n = tune(),
    tree_depth = tune(), 
    learn_rate = tune()
  ) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")

boost_grid <- grid_regular(min_n(),
                          tree_depth(),
                          learn_rate(),
                          levels = 3)

boost_wf <- workflow() %>%
  add_model(boost_tune_spec) %>%
  add_recipe(knn_rec)

boost_res <- boost_wf %>% 
  tune_grid(
    resamples = folds,
    grid = boost_grid
    )

boost_res %>%
  collect_metrics() %>%
  filter(.metric == "accuracy")

boost_res %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  mutate(tree_depth = factor(tree_depth)) %>%
  ggplot(aes(learn_rate, mean, color = tree_depth)) +
  geom_line(size = 1.5, alpha = 0.6) +
  geom_point(size = 2) +
  facet_wrap(~ min_n, labeller = label_both) +
  scale_color_viridis_d(option = "plasma", begin = .9, end = 0) +
  scale_x_log10(labels = scales::label_number()) +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(title = "Accuracy across different hyperparameter values",
       x = "log10(Learn rate)",
       y = "Mean accuracy",
       color = "Tree depth")
```
can see that highest accuracy comes from min_n of 2. looking closer, see that tree depth of 8 & log10(learn rate) of around .00001 gave best


```{r boost_best}
# then choose the best model to finish tuning
best_boost <- boost_res %>%
  select_best("accuracy")

best_boost %>%
  select(-.config) %>%
  knitr::kable(
    caption = "Hyperparameter values maximizing accuracy in boosted tree model", 
    col.names = c(
      "Minimum n to split at node",
      "Tree depth", 
      "Learning rate"))

final_boost_wf <- boost_wf %>%
  finalize_workflow(best_boost)

# fit best model to training data
final_boost <- final_boost_wf %>%
  fit(data = gss_train)

# can see how important each var is here
final_tree %>% 
  pull_workflow_fit() %>% 
  vip() +
  labs(title = "Important variables\nin final boosted tree model") 

# last fit & eval of model performance
final_boost_wf %>%
  last_fit(gss_split) %>%
  collect_metrics() %>%
  filter(.metric == "accuracy")

```

```{r}
library(tidyverse)
library(tidymodels)
library(rcfss)
data("gss", package = "rcfss")
# splitting data
set.seed(123)
gss_split <- initial_split(gss, strata = colrac)

gss_train <- training(gss_split)
gss_test <- testing(gss_split)

folds <- vfold_cv(gss_train, v = 10)
#set up of log model
lr_mod <- logistic_reg() %>% 
  set_engine("glm")

colrac_lr_wf <- workflow() %>%
  add_model(lr_mod) %>%
  add_formula(colrac ~ 
                age + black + degree + partyid_3 + sex + south)

lr_fit_rs <- colrac_lr_wf %>%
  fit_resamples(folds)

# writing function
find_accuracy <- function(df, modeltype) {
  df %>%
  collect_metrics %>%
    filter(.metric == "accuracy") %>%
    select(c(-n, -.estimator, -std_err, -.config)) %>%
    add_column(type = {"modeltype"}) # PROBLEM ARISES HERE
}

# testing func
find_accuracy(lr_fit_rs) #%>%
  add_column(type = "logistic")

comb_ridge %>% ridge_rs %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%


bind_rows(knn_res, lr_res, ridge_rs) 

knn_res
  
```
so it seems that random_forest gave best model. predicted about 79% of data correctly. logistic gave worst (53% accuracy()), probably cuz it didn't use all var in dataset as predictor var (so less of the variation could've been explained).
for models that included all available vars as predictors, knn did worst. 
even tuning didn't help boosted tree model do better than random forest (tuned boosted tree got 75% right) or even ridge model, indicating that there's a limit to how far tuning will get you if your model overall doesn't work that well. 


## Session info

```{r}
devtools::session_info()
```
