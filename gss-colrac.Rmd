---
title: "Predicting Attitudes Towards Racist College Professors"
author: "Julia Du"
date: "`r lubridate::today()`"
output: 
  github_document:
    toc: true
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(message = FALSE)
```

## Load necessary libraries

```{r packages}
library(tidyverse)
library(tidymodels)
library(rcfss)
library(usemodels)
library(kknn)
library(glmnet)
library(xgboost)
library(vip)
library(lubridate)

# load correct gss data frame
data("gss", package = "rcfss")

theme_set(theme_minimal())
```


```{r oof}
# setting seed for all of this doc
set.seed(123)

# splitting data
gss_split <- initial_split(gss, strata = colrac)

gss_train <- training(gss_split)
gss_test <- testing(gss_split)

folds <- vfold_cv(gss_train, v = 10)
```

## Logistic regression
```{r log_reg}
# build a log model specification
lr_mod <- logistic_reg() %>% 
  set_engine("glm")

# resample via a workflow
colrac_lr_wf <- workflow() %>%
  add_model(lr_mod) %>%
  add_formula(colrac ~ 
                age + black + degree + partyid_3 + sex + south)

lr_fit_rs <- colrac_lr_wf %>%
  fit_resamples(folds)

lr_fit_rs %>%
  collect_metrics() %>%
  filter(.metric == "accuracy")
```

## Random forest
```{r random_forest}
# random forest template  
# doesn't actually do anything, but good for reference
#use_ranger(colrac  ~ ., data = gss_train, verbose = TRUE, tune = FALSE)

# build a random forest model specification
rf_mod <- rand_forest(trees = 1000) %>% 
  set_engine("ranger") %>% 
  set_mode("classification")

rf_rec <- recipe(colrac ~ ., data = gss_train) %>% 
  update_role(id, wtss, new_role = "ID") %>%
  step_naomit(colrac, skip = TRUE) %>%
  step_medianimpute(all_numeric()) %>%
  step_modeimpute(all_nominal(), -all_outcomes()) %>%
  step_cut(cohort, breaks = c(1945, 1964, 1980))

rf_wf <- workflow() %>%
  add_model(rf_mod) %>%
  add_recipe(rf_rec)

rf_rs <- rf_wf %>%
  fit_resamples(folds) 

rf_rs %>%
  collect_metrics() %>% 
  filter(.metric == "accuracy")
```

## 5-nearest neighbors
```{r knn}
# template for kknn
#use_kknn(colrac ~ ., data = gss_train, verbose = TRUE, tune = FALSE)

knn_mod <- nearest_neighbor(neighbors = 5) %>%              
  set_engine("kknn") %>%             
  set_mode("classification")      

knn_rec <- recipe(formula = colrac ~ ., data = gss_train) %>% 
  update_role(id, wtss, new_role = "ID") %>%
  step_naomit(colrac, skip = TRUE) %>%
  step_medianimpute(all_numeric()) %>%
  step_modeimpute(all_nominal(), -all_outcomes()) %>%
  step_cut(cohort, breaks = c(1945, 1964, 1980)) %>%
  step_novel(all_nominal(), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_zv(all_predictors()) %>% 
  step_normalize(all_predictors(), -all_nominal()) 

knn_wf <- workflow() %>%
  add_model(knn_mod) %>%
  add_recipe(knn_rec)

knn_rs <- knn_wf %>%
  fit_resamples(folds) 

knn_rs %>%
  collect_metrics() %>%
  filter(.metric == "accuracy")
```

## Ridge logistic regression
```{r ridge}
ridge_mod <- logistic_reg(penalty = .01, mixture = 0) %>% 
  set_engine("glmnet") %>% # use glmnet over glm since we have a penalty
  set_mode("classification")

# using same recipe as knn
ridge_rs <- update_model(knn_wf, ridge_mod) %>%
  fit_resamples(folds) 

ridge_rs %>%
  collect_metrics() %>%
  filter(.metric == "accuracy")
```

## Tuned boosted tree
```{r tune_boost_tree, cache = TRUE}
boost_tune_spec <- 
  boost_tree(
  #  min_n = tune(),
    tree_depth = tune(), 
    learn_rate = tune()
  ) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")

boost_grid <- grid_regular(#min_n(),
                          tree_depth(),
                          learn_rate(),
                          levels = 3)
# originally included min_n() in hyperparameters,
# but was unable to knit on MACSS R server 

boost_wf <- workflow() %>%
  add_model(boost_tune_spec) %>%
  add_recipe(knn_rec)

boost_res <- boost_wf %>% 
  tune_grid(
    resamples = folds,
    grid = boost_grid
    )

boost_res %>%
  collect_metrics() %>%
  filter(.metric == "accuracy")

boost_res %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  mutate(tree_depth = factor(tree_depth)) %>%
  ggplot(aes(learn_rate, mean, color = tree_depth)) +
  geom_line(size = 1.5, alpha = 0.6) +
  geom_point(size = 2) +
 # facet_wrap(~ min_n, labeller = label_both) +
  scale_color_viridis_d(option = "plasma", begin = .9, end = 0) +
  scale_x_log10(labels = scales::label_number()) +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(title = "Accuracy across different hyperparameter values",
       x = "log10(Learn rate)",
       y = "Mean accuracy" ,
       color = "Tree depth"
       )
```

Note: for my tuned boosted tree model, I'd originally included min_n as one of the hyperparameters, but I was forced to leave it out because the MACSS R server was unable to knit with so many hyperparameters. While I managed to run the code & get my specified output with 3 hyperparametrs, knitting didn't work. I've left my original code of 3 hyperparameters as comments, in case you're curious and want to try it out on your own computer.

From the graph, we can see that a tree depth of 8 & log10(learn rate) of around .01 gave the best accuracy of all tested boosted tree models.


```{r boost_best, warning = FALSE}
# then choose the best model to finish tuning
best_boost <- boost_res %>%
  select_best("accuracy")

best_boost %>%
  select(-.config) %>%
  knitr::kable(
    caption = "Hyperparameter values maximizing accuracy in boosted tree model", 
    col.names = c(
  #    "Minimum n to split at node",
      "Tree depth", 
      "Learning rate"))

final_boost_wf <- boost_wf %>%
  finalize_workflow(best_boost)

# fit best model to training data
final_boost <- final_boost_wf %>%
  fit(data = gss_train)

# can see how important each var is here
final_boost %>% 
  pull_workflow_fit() %>% 
  vip() +
  labs(title = "Important variables\nin final boosted tree model") 

# last fit & eval of model performance
final_fit <- final_boost_wf %>%
  last_fit(gss_split) 

final_fit %>%
  collect_metrics() %>%
  filter(.metric == "accuracy")
```

The importance graph shows which variables are most important in driving predictions on the racist college professors question for this model - tolerance seems especially important, which seems logical.


## Comparing models
```{r compare_models}
# writing function
find_accuracy <- function(df, modeltype) {
  df %>%
  collect_metrics %>%
    filter(.metric == "accuracy") %>%
    add_column(type = modeltype) %>%
    select(c(type, mean)) 
}

# assembling table of all accuracy figures
compare_accuracy <- final_fit %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  rename(mean = .estimate) %>%
  add_column(type = "boosted tree") %>%
  select(c(type, mean)) %>%
  bind_rows(
    find_accuracy(lr_fit_rs, "logistic"),
    find_accuracy(rf_rs, "random forest"), 
    find_accuracy(knn_rs, "knn"), 
    find_accuracy(ridge_rs, "ridge logistic")
    ) %>%
  arrange(desc(mean)) 

compare_accuracy %>%
  mutate(mean = mean * 100) %>%
  knitr::kable(
    caption = "Accuracy across models", 
    col.names = c(
      "Model type",
      "Percentage of data predicted correctly"), 
    digits = 3)
```

After reducing down to only 2 hyperparameters, the tuned boosted tree model did the best overall, with a mean accuracy of 80%. 

Random forest also gave a quite accurate model, predicting about 79% of data correctly. The logistic regression did the worst (53% accuracy), probably because it, unlike all other models built here, didn't use all variables in the dataset as predictor variables. The logistic regression only used the age, black, degree, partyid_3, sex, and south variables as predictors - so less of the variation in the outcome variable would've been explained.

All these accuracy figures seem quite reasonable - they aren't overly optimistic, which could imply overfitting the data. Instead, they mostly hover around the upper 70% range, with the basic logistic model doing poorly due to only using a few predictor variables & the 5-nearest neighbors underperforming (with an accuracy of 61%) in comparison to the other models that used all available variables as predictors.

## Session info

```{r}
devtools::session_info()
```
